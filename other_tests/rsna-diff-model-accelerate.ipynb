{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# convenience directory variables\nTRAIN_DIR = '/kaggle/input/rsna-2023-atd-reduced-256-5mm/reduced_256_tickness_5'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-25T15:24:15.243598Z","iopub.execute_input":"2023-08-25T15:24:15.245368Z","iopub.status.idle":"2023-08-25T15:24:15.256013Z","shell.execute_reply.started":"2023-08-25T15:24:15.245340Z","shell.execute_reply":"2023-08-25T15:24:15.254776Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport PIL\nimport matplotlib.pyplot as plt\nimport cv2\nfrom tqdm.notebook import tqdm\nimport shutil","metadata":{"execution":{"iopub.status.busy":"2023-08-25T15:24:15.278218Z","iopub.execute_input":"2023-08-25T15:24:15.278472Z","iopub.status.idle":"2023-08-25T15:24:15.624383Z","shell.execute_reply.started":"2023-08-25T15:24:15.278449Z","shell.execute_reply":"2023-08-25T15:24:15.623436Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/rsna-2023-abdominal-trauma-detection/train.csv\")\ntrain.tail()","metadata":{"execution":{"iopub.status.busy":"2023-08-25T15:24:15.626546Z","iopub.execute_input":"2023-08-25T15:24:15.626900Z","iopub.status.idle":"2023-08-25T15:24:15.664421Z","shell.execute_reply.started":"2023-08-25T15:24:15.626868Z","shell.execute_reply":"2023-08-25T15:24:15.663308Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"      patient_id  bowel_healthy  bowel_injury  extravasation_healthy  \\\n3142        9951              1             0                      1   \n3143        9960              1             0                      1   \n3144        9961              1             0                      1   \n3145        9980              1             0                      1   \n3146        9983              1             0                      1   \n\n      extravasation_injury  kidney_healthy  kidney_low  kidney_high  \\\n3142                     0               1           0            0   \n3143                     0               1           0            0   \n3144                     0               1           0            0   \n3145                     0               1           0            0   \n3146                     0               1           0            0   \n\n      liver_healthy  liver_low  liver_high  spleen_healthy  spleen_low  \\\n3142              1          0           0               1           0   \n3143              1          0           0               1           0   \n3144              1          0           0               1           0   \n3145              1          0           0               0           0   \n3146              1          0           0               0           0   \n\n      spleen_high  any_injury  \n3142            0           0  \n3143            0           0  \n3144            0           0  \n3145            1           1  \n3146            1           1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>patient_id</th>\n      <th>bowel_healthy</th>\n      <th>bowel_injury</th>\n      <th>extravasation_healthy</th>\n      <th>extravasation_injury</th>\n      <th>kidney_healthy</th>\n      <th>kidney_low</th>\n      <th>kidney_high</th>\n      <th>liver_healthy</th>\n      <th>liver_low</th>\n      <th>liver_high</th>\n      <th>spleen_healthy</th>\n      <th>spleen_low</th>\n      <th>spleen_high</th>\n      <th>any_injury</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3142</th>\n      <td>9951</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3143</th>\n      <td>9960</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3144</th>\n      <td>9961</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3145</th>\n      <td>9980</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3146</th>\n      <td>9983</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_series_meta = pd.read_csv(\"/kaggle/input/rsna-2023-abdominal-trauma-detection/train_series_meta.csv\")\nprint(\"Number of unique patients in train dataset: \", len(train_series_meta['patient_id'].unique()))\nprint(\"Number of samples in train dataset: \", len(train_series_meta['patient_id']))\ntrain_series_meta.head(100)","metadata":{"execution":{"iopub.status.busy":"2023-08-25T15:24:15.666144Z","iopub.execute_input":"2023-08-25T15:24:15.666509Z","iopub.status.idle":"2023-08-25T15:24:15.706119Z","shell.execute_reply.started":"2023-08-25T15:24:15.666476Z","shell.execute_reply":"2023-08-25T15:24:15.705103Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Number of unique patients in train dataset:  3147\nNumber of samples in train dataset:  4711\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"    patient_id  series_id  aortic_hu  incomplete_organ\n0        10004      21057     146.00                 0\n1        10004      51033     454.75                 0\n2        10005      18667     187.00                 0\n3        10007      47578     329.00                 0\n4        10026      29700     327.00                 0\n..         ...        ...        ...               ...\n95       11312      51300     179.00                 0\n96       11313      48992     297.00                 0\n97       11335      24276     111.00                 0\n98       11335      39434     216.00                 0\n99       11361       2204     124.00                 0\n\n[100 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>patient_id</th>\n      <th>series_id</th>\n      <th>aortic_hu</th>\n      <th>incomplete_organ</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10004</td>\n      <td>21057</td>\n      <td>146.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10004</td>\n      <td>51033</td>\n      <td>454.75</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10005</td>\n      <td>18667</td>\n      <td>187.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10007</td>\n      <td>47578</td>\n      <td>329.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10026</td>\n      <td>29700</td>\n      <td>327.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>11312</td>\n      <td>51300</td>\n      <td>179.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>11313</td>\n      <td>48992</td>\n      <td>297.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>11335</td>\n      <td>24276</td>\n      <td>111.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>11335</td>\n      <td>39434</td>\n      <td>216.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>11361</td>\n      <td>2204</td>\n      <td>124.00</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"image_level_labels = pd.read_csv(\"/kaggle/input/rsna-2023-abdominal-trauma-detection/image_level_labels.csv\")\nprint(\"Unique series: \", len(image_level_labels['series_id'].unique()))\nimage_level_labels.head(1000)","metadata":{"execution":{"iopub.status.busy":"2023-08-25T15:24:15.708816Z","iopub.execute_input":"2023-08-25T15:24:15.710195Z","iopub.status.idle":"2023-08-25T15:24:15.740659Z","shell.execute_reply.started":"2023-08-25T15:24:15.710163Z","shell.execute_reply":"2023-08-25T15:24:15.739799Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Unique series:  330\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"     patient_id  series_id  instance_number           injury_name\n0         10004      21057              362  Active_Extravasation\n1         10004      21057              363  Active_Extravasation\n2         10004      21057              364  Active_Extravasation\n3         10004      21057              365  Active_Extravasation\n4         10004      21057              366  Active_Extravasation\n..          ...        ...              ...                   ...\n995       12332      15276               60                 Bowel\n996       12332      15276               61                 Bowel\n997       12332      15276               62                 Bowel\n998       12332      15276               63                 Bowel\n999       12332      15276               64                 Bowel\n\n[1000 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>patient_id</th>\n      <th>series_id</th>\n      <th>instance_number</th>\n      <th>injury_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10004</td>\n      <td>21057</td>\n      <td>362</td>\n      <td>Active_Extravasation</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10004</td>\n      <td>21057</td>\n      <td>363</td>\n      <td>Active_Extravasation</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10004</td>\n      <td>21057</td>\n      <td>364</td>\n      <td>Active_Extravasation</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10004</td>\n      <td>21057</td>\n      <td>365</td>\n      <td>Active_Extravasation</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10004</td>\n      <td>21057</td>\n      <td>366</td>\n      <td>Active_Extravasation</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>12332</td>\n      <td>15276</td>\n      <td>60</td>\n      <td>Bowel</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>12332</td>\n      <td>15276</td>\n      <td>61</td>\n      <td>Bowel</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>12332</td>\n      <td>15276</td>\n      <td>62</td>\n      <td>Bowel</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>12332</td>\n      <td>15276</td>\n      <td>63</td>\n      <td>Bowel</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>12332</td>\n      <td>15276</td>\n      <td>64</td>\n      <td>Bowel</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_d = train.loc[(train['kidney_healthy']==1) & (train['liver_healthy']==1) & (train['spleen_healthy']==1) & (train['any_injury']==0)]\ntrain_d = train_series_meta.merge(train_d, on='patient_id', how='right')\ntrain_d = train_d.loc[train_d['incomplete_organ']==0]","metadata":{"execution":{"iopub.status.busy":"2023-08-25T15:24:15.742018Z","iopub.execute_input":"2023-08-25T15:24:15.742660Z","iopub.status.idle":"2023-08-25T15:24:15.761185Z","shell.execute_reply.started":"2023-08-25T15:24:15.742626Z","shell.execute_reply":"2023-08-25T15:24:15.760321Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"paths = []\nfor _, row in tqdm(train_d.iterrows(), total = len(train_d)):\n    path = f\"{TRAIN_DIR}/{int(row['patient_id'])}/{int(row['series_id'])}\"\n    images = os.listdir(path)\n    filenames = [int(filename.split('.')[0]) for filename in images]\n    images = list(map(lambda x: str(x)+'.jpeg', sorted(filenames)))\n    [paths.append(f\"{path}/{image}\") for image in images]\n","metadata":{"execution":{"iopub.status.busy":"2023-08-25T15:24:15.762784Z","iopub.execute_input":"2023-08-25T15:24:15.763451Z","iopub.status.idle":"2023-08-25T15:26:08.288629Z","shell.execute_reply.started":"2023-08-25T15:24:15.763417Z","shell.execute_reply":"2023-08-25T15:26:08.287626Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50c7e8bcbf934beebbf39de88a68e7e7"}},"metadata":{}}]},{"cell_type":"code","source":"len(paths)","metadata":{"execution":{"iopub.status.busy":"2023-08-25T15:26:08.290137Z","iopub.execute_input":"2023-08-25T15:26:08.290469Z","iopub.status.idle":"2023-08-25T15:26:08.297785Z","shell.execute_reply.started":"2023-08-25T15:26:08.290437Z","shell.execute_reply":"2023-08-25T15:26:08.296676Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"335180"},"metadata":{}}]},{"cell_type":"code","source":"import albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\nimport random\nimport numpy as np\nfrom tqdm.notebook import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-08-25T15:26:08.299385Z","iopub.execute_input":"2023-08-25T15:26:08.300249Z","iopub.status.idle":"2023-08-25T15:26:11.865714Z","shell.execute_reply.started":"2023-08-25T15:26:08.300216Z","shell.execute_reply":"2023-08-25T15:26:11.864723Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport glob\nimport torch\nfrom PIL import Image\n\nclass DiffDataset(torch.utils.data.Dataset):\n\n    def __init__(self, paths:list[str], transforms = None, limit:int = None, normalize=True):\n        \n        self.limit = limit\n        self.transforms = transforms\n        self.normalize = normalize\n        self.image_paths = paths\n        if limit:\n            self.image_paths = self.image_paths[0:limit]\n    \n    def __getitem__(self, index: int)->tuple[np.ndarray, np.ndarray]:\n        img = np.array(Image.open(self.image_paths[index]), dtype = np.float32)\n        \n        if self.normalize:\n            img = img/255.0\n            \n        if self.transforms is not None:\n            augmented = self.transforms(image=img)\n            img = augmented['image']\n            img.unsqueeze(0)\n        return img\n    \n    def __len__(self):\n        return(len(self.image_paths))","metadata":{"execution":{"iopub.status.busy":"2023-08-25T15:26:11.867298Z","iopub.execute_input":"2023-08-25T15:26:11.867985Z","iopub.status.idle":"2023-08-25T15:26:11.877327Z","shell.execute_reply.started":"2023-08-25T15:26:11.867934Z","shell.execute_reply":"2023-08-25T15:26:11.876294Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"!pip install denoising_diffusion_pytorch\n!pip install git+https://github.com/huggingface/accelerate","metadata":{"execution":{"iopub.status.busy":"2023-08-25T15:26:11.881671Z","iopub.execute_input":"2023-08-25T15:26:11.882100Z","iopub.status.idle":"2023-08-25T15:26:52.046936Z","shell.execute_reply.started":"2023-08-25T15:26:11.882069Z","shell.execute_reply":"2023-08-25T15:26:52.045763Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Collecting denoising_diffusion_pytorch\n  Downloading denoising_diffusion_pytorch-1.8.9-py3-none-any.whl (56 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from denoising_diffusion_pytorch) (0.20.3)\nCollecting einops (from denoising_diffusion_pytorch)\n  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting ema-pytorch (from denoising_diffusion_pytorch)\n  Downloading ema_pytorch-0.2.3-py3-none-any.whl (4.4 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from denoising_diffusion_pytorch) (1.23.5)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from denoising_diffusion_pytorch) (9.5.0)\nCollecting pytorch-fid (from denoising_diffusion_pytorch)\n  Downloading pytorch_fid-0.3.0-py3-none-any.whl (15 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from denoising_diffusion_pytorch) (2.0.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from denoising_diffusion_pytorch) (0.15.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from denoising_diffusion_pytorch) (4.65.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate->denoising_diffusion_pytorch) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->denoising_diffusion_pytorch) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate->denoising_diffusion_pytorch) (6.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->denoising_diffusion_pytorch) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->denoising_diffusion_pytorch) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->denoising_diffusion_pytorch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->denoising_diffusion_pytorch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->denoising_diffusion_pytorch) (3.1.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from pytorch-fid->denoising_diffusion_pytorch) (1.11.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision->denoising_diffusion_pytorch) (2.31.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate->denoising_diffusion_pytorch) (3.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->denoising_diffusion_pytorch) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->denoising_diffusion_pytorch) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->denoising_diffusion_pytorch) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->denoising_diffusion_pytorch) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->denoising_diffusion_pytorch) (2023.5.7)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->denoising_diffusion_pytorch) (1.3.0)\nInstalling collected packages: einops, ema-pytorch, pytorch-fid, denoising_diffusion_pytorch\nSuccessfully installed denoising_diffusion_pytorch-1.8.9 einops-0.6.1 ema-pytorch-0.2.3 pytorch-fid-0.3.0\nCollecting git+https://github.com/huggingface/accelerate\n  Cloning https://github.com/huggingface/accelerate to /tmp/pip-req-build-4gkgwchs\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate /tmp/pip-req-build-4gkgwchs\n  Resolved https://github.com/huggingface/accelerate to commit e2ae254008061b3e53fc1c97f88d65743a857e75\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.23.0.dev0) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.23.0.dev0) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.23.0.dev0) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate==0.23.0.dev0) (6.0)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.23.0.dev0) (2.0.0)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate==0.23.0.dev0) (0.16.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate==0.23.0.dev0) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.23.0.dev0) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.23.0.dev0) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.23.0.dev0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.23.0.dev0) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.23.0.dev0) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.23.0.dev0) (2023.6.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.23.0.dev0) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.23.0.dev0) (4.65.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.23.0.dev0) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.23.0.dev0) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.23.0.dev0) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.23.0.dev0) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.23.0.dev0) (2023.5.7)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.23.0.dev0) (1.3.0)\nBuilding wheels for collected packages: accelerate\n  Building wheel for accelerate (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for accelerate: filename=accelerate-0.23.0.dev0-py3-none-any.whl size=255448 sha256=7bc5c28fa1af0f6eaad7614624297e04b078227563f1597f6a33c07c0f4e446a\n  Stored in directory: /tmp/pip-ephem-wheel-cache-0zp_9w7c/wheels/f6/c7/9d/1b8a5ca8353d9307733bc719107acb67acdc95063bba749f26\nSuccessfully built accelerate\nInstalling collected packages: accelerate\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.20.3\n    Uninstalling accelerate-0.20.3:\n      Successfully uninstalled accelerate-0.20.3\nSuccessfully installed accelerate-0.23.0.dev0\n","output_type":"stream"}]},{"cell_type":"code","source":"from accelerate import Accelerator, notebook_launcher\nfrom accelerate.utils import set_seed\n\nfrom denoising_diffusion_pytorch import Unet, ElucidatedDiffusion\nfrom ema_pytorch import EMA\n\nfrom torch.optim import Adam\nfrom torch.utils.data import DataLoader, Sampler\n\nfrom multiprocessing import cpu_count\nfrom pathlib import Path\n\nimport torch.nn as nn\n","metadata":{"execution":{"iopub.status.busy":"2023-08-25T15:26:52.049433Z","iopub.execute_input":"2023-08-25T15:26:52.049820Z","iopub.status.idle":"2023-08-25T15:27:03.628428Z","shell.execute_reply.started":"2023-08-25T15:26:52.049783Z","shell.execute_reply":"2023-08-25T15:27:03.627411Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"def construct_dataset(paths, transforms = None, limit: int = None, normalize = True):    \n    # For training a simple RandomResizedCrop will be used\n    assert len(paths) > 1000, \"Dataset must have more than 1000 images.\"\n    if not transforms:\n        transforms = A.Compose([\n            ToTensorV2()\n        ])\n    \n    return DiffDataset(paths, transforms = transforms, limit = limit, normalize = normalize)","metadata":{"execution":{"iopub.status.busy":"2023-08-25T15:27:03.630049Z","iopub.execute_input":"2023-08-25T15:27:03.630455Z","iopub.status.idle":"2023-08-25T15:27:03.637349Z","shell.execute_reply.started":"2023-08-25T15:27:03.630412Z","shell.execute_reply":"2023-08-25T15:27:03.636028Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def construct_network():\n    unet = Unet(dim=64, dim_mults=(1, 2, 4, 8), channels=1, learned_sinusoidal_dim = 16, \n                learned_sinusoidal_cond = True, random_fourier_features = False, attn_dim_head = 16,\n               resnet_block_groups = 2, attn_heads = 1, learned_variance = True)\n    model = ElucidatedDiffusion(\n        unet,\n        image_size=256,\n        channels = 1,\n        num_sample_steps = 34, # number of sampling steps\n        sigma_min = 0.002,     # min noise level\n        sigma_max = 40,        # max noise level\n        sigma_data = 0.5,      # standard deviation of data distribution\n        rho = 7,               # controls the sampling schedule\n        P_mean = -1.2,         # mean of log-normal distribution from which noise is drawn for training\n        P_std = 1.2,           # standard deviation of log-normal distribution from which noise is drawn for training\n        S_churn = 80,          # parameters for stochastic sampling - depends on dataset, Table 5 in apper\n        S_tmin = 0.05,\n        S_tmax = 50,\n        S_noise = 1.003,\n    )\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-08-25T15:27:03.772799Z","iopub.execute_input":"2023-08-25T15:27:03.773197Z","iopub.status.idle":"2023-08-25T15:27:03.786464Z","shell.execute_reply.started":"2023-08-25T15:27:03.773167Z","shell.execute_reply":"2023-08-25T15:27:03.785255Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"#a = construct_dataset(paths)\n#t_im = a[1000]#.squeeze().numpy()\n#t_im.shape\n#plt.imshow(t_im)","metadata":{"execution":{"iopub.status.busy":"2023-08-25T15:27:03.656748Z","iopub.execute_input":"2023-08-25T15:27:03.657086Z","iopub.status.idle":"2023-08-25T15:27:03.669183Z","shell.execute_reply.started":"2023-08-25T15:27:03.657051Z","shell.execute_reply":"2023-08-25T15:27:03.667982Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#net = construct_network()","metadata":{"execution":{"iopub.status.busy":"2023-08-25T15:27:03.670710Z","iopub.execute_input":"2023-08-25T15:27:03.671142Z","iopub.status.idle":"2023-08-25T15:27:03.680336Z","shell.execute_reply.started":"2023-08-25T15:27:03.671111Z","shell.execute_reply":"2023-08-25T15:27:03.679160Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"#from einops import rearrange, repeat, reduce","metadata":{"execution":{"iopub.status.busy":"2023-08-25T15:27:03.681772Z","iopub.execute_input":"2023-08-25T15:27:03.682468Z","iopub.status.idle":"2023-08-25T15:27:03.692611Z","shell.execute_reply.started":"2023-08-25T15:27:03.682432Z","shell.execute_reply":"2023-08-25T15:27:03.691395Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"def normalize_to_neg_one_to_one(img):\n    return img * 2 - 1\n\ndef ff(net, images):\n    batch_size, c, h, w, device, image_size, channels = *images.shape, images.device, net.image_size, net.channels\n\n    assert h == image_size and w == image_size, f'height and width of image must be {image_size}'\n    assert c == channels, 'mismatch of image channels'\n\n    images = normalize_to_neg_one_to_one(images)\n\n    sigmas = net.noise_distribution(batch_size)\n    padded_sigmas = rearrange(sigmas, 'b -> b 1 1 1')\n\n    noise = torch.randn_like(images)\n\n    noised_images = images + padded_sigmas * noise  # alphas are 1. in the paper\n    \n    self_cond = None\n    denoised = net.preconditioned_network_forward(noised_images, sigmas, self_cond)\n    return noised_images, denoised","metadata":{"execution":{"iopub.status.busy":"2023-08-24T13:50:35.372051Z","iopub.execute_input":"2023-08-24T13:50:35.373644Z","iopub.status.idle":"2023-08-24T13:50:35.388591Z","shell.execute_reply.started":"2023-08-24T13:50:35.373469Z","shell.execute_reply":"2023-08-24T13:50:35.387173Z"},"_kg_hide-input":true}},{"cell_type":"code","source":"#noised, denoised = ff(net, a[1000].unsqueeze(0))","metadata":{"execution":{"iopub.status.busy":"2023-08-25T15:27:03.695851Z","iopub.execute_input":"2023-08-25T15:27:03.696222Z","iopub.status.idle":"2023-08-25T15:27:03.705412Z","shell.execute_reply.started":"2023-08-25T15:27:03.696195Z","shell.execute_reply":"2023-08-25T15:27:03.704326Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#plt.imshow(noised.squeeze().detach().numpy())","metadata":{"execution":{"iopub.status.busy":"2023-08-25T15:27:03.708968Z","iopub.execute_input":"2023-08-25T15:27:03.709317Z","iopub.status.idle":"2023-08-25T15:27:03.717992Z","shell.execute_reply.started":"2023-08-25T15:27:03.709293Z","shell.execute_reply":"2023-08-25T15:27:03.717007Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def get_rank():\n    return torch.distributed.get_rank() if torch.distributed.is_initialized() else 0\n\n\ndef get_world_size():\n    return torch.distributed.get_world_size() if torch.distributed.is_initialized() else 1\n\ndef exists(x):\n    return x is not None\n\nclass InfiniteSampler(torch.utils.data.Sampler):\n    def __init__(self, dataset, rank=0, num_replicas=1, shuffle=True, seed=0, window_size=0.5):\n        assert len(dataset) > 0\n        assert num_replicas > 0\n        assert 0 <= rank < num_replicas\n        assert 0 <= window_size <= 1\n        super().__init__(dataset)\n        self.dataset = dataset\n        self.rank = rank\n        self.num_replicas = num_replicas\n        self.shuffle = shuffle\n        self.seed = seed\n        self.window_size = window_size\n\n    def __iter__(self):\n        order = np.arange(len(self.dataset))\n        rnd = None\n        window = 0\n        if self.shuffle:\n            rnd = np.random.RandomState(self.seed)\n            rnd.shuffle(order)\n            window = int(np.rint(order.size * self.window_size))\n\n        idx = 0\n        while True:\n            i = idx % order.size\n            if idx % self.num_replicas == self.rank:\n                yield order[i]\n            if window >= 2:\n                j = (i - rnd.randint(window)) % order.size\n                order[i], order[j] = order[j], order[i]\n            idx += 1\n","metadata":{"execution":{"iopub.status.busy":"2023-08-25T15:27:03.719484Z","iopub.execute_input":"2023-08-25T15:27:03.720182Z","iopub.status.idle":"2023-08-25T15:27:03.734560Z","shell.execute_reply.started":"2023-08-25T15:27:03.720121Z","shell.execute_reply":"2023-08-25T15:27:03.733623Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import os\nimport time\nimport copy\nimport json\nimport pickle\nimport psutil\nimport numpy as np\nimport torch\n\n#----------------------------------------------------------------------------\n\ndef train(\n    run_dir             = './results',      # Output directory.\n    dataset_options     = {'paths':paths, 'transforms': None, 'limit': None, 'normalize': True},       # Option for dataset creator \n    network_kwargs      = {},       # Options for model.\n    optimizer_kwargs    = {'lr': 1e-4, 'betas': (0.9, 0.99)},       # Options for optimizer.\n    ema_kwargs          = {'ema_beta': 0.995, 'ema_halflife_kimg': 500, 'ema_rampup_ratio': 0.05},\n    split_batches       = True,     # Split batches?\n    mixes_pecision      = 'fp16',\n    seed                = 12,        # Global random seed.\n    batch_size:int      = 240,      # Total batch size for one training iteration.\n    total_kimg          = 50000,   # Training duration, measured in thousands of training images.\n    #ema_halflife_kimg   Half-life of the exponential moving average (EMA) of model weights.\n    #ema_rampup_ratio    EMA ramp-up coefficient, None = no rampup.\n    lr_rampup_kimg      = 10000,    # Learning rate ramp-up duration.\n    loss_scaling        = 1,        # Loss scaling factor for reducing FP16 under/overflows.\n    snapshot_ticks      = 100,       # How often to save network snapshots, None = disable.\n    resume_pkl          = '/kaggle/working/results/model-save.pt',     # Start from the given network snapshot, None = random initialization.\n    resume_kimg         = 0,        # Start from the given training progress.\n    batch_gpu           = 8,      # Limit batch size per GPU, None = no limit.\n    max_training_time   = 6      # Maximum training time, in hours.\n):\n\n    # Initialize accelerator.\n    accelerator = Accelerator(\n        split_batches = split_batches,\n        mixed_precision = 'fp16'\n    )\n    device = accelerator.device\n    \n    if accelerator.is_main_process:\n        results_folder = Path(run_dir)\n        results_folder.mkdir(exist_ok = True)\n\n    # Select batch size per GPU.\n    accelerator.print(\"Splitting batches...\")\n    batch_gpu_total = batch_size // get_world_size() #6\n    if batch_gpu is None or batch_gpu > batch_gpu_total:\n        batch_gpu = batch_gpu_total\n    num_accumulation_rounds = batch_gpu_total // batch_gpu\n    #accelerator.print(batch_gpu, num_accumulation_rounds)\n    assert batch_size == batch_gpu * num_accumulation_rounds * get_world_size()\n    accelerator.print(f\"batch_size: {batch_gpu}, num_accumulation_rounds: {num_accumulation_rounds}, batch_gpu_total: {batch_gpu_total}\")\n\n    # Load dataset.\n    accelerator.print('Loading dataset...')\n    dataset_obj = construct_dataset(**dataset_options)\n    dataset_sampler = InfiniteSampler(dataset=dataset_obj, rank=get_rank(), num_replicas=get_world_size(), seed=seed)\n    dataset_iterator = iter(torch.utils.data.DataLoader(dataset=dataset_obj, sampler=dataset_sampler, batch_size=batch_gpu))\n\n    # Construct network.\n    accelerator.print('Constructing network...')\n    net = construct_network()\n    \n    # Setup optimizer.\n    accelerator.print('Setting up optimizer...')\n    optimizer =  Adam(net.parameters(), **optimizer_kwargs)\n    \n    # Accelerator prepare\n    net, optimizer, dataset_iterator = accelerator.prepare(\n        net, optimizer, dataset_iterator\n    )\n    \n    \n    if accelerator.is_main_process:\n        ema_beta = ema_kwargs['ema_beta']\n        ema_halflife_kimg = ema_kwargs['ema_halflife_kimg']\n        ema_rampup_ratio=ema_kwargs['ema_rampup_ratio']\n        ema = copy.deepcopy(net).eval().requires_grad_(False)\n        #ema.to(device)\n\n    # Resume training from previous snapshot.\n    if resume_pkl is not None:\n        data = torch.load(resume_pkl, map_location=device)\n        m = accelerator.unwrap_model(net)\n        net.load_state_dict(data['model'])\n        resume_kimg = data['kimg']\n        optimizer.load_state_dict(data['opt'])\n        if accelerator.is_main_process:\n            ema.load_state_dict(data[\"ema\"])\n        if 'version' in data:\n            print(f\"loading from version {data['version']}\")\n        if exists(accelerator.scaler) and exists(data['scaler']):\n            accelerator.scaler.load_state_dict(data['scaler'])\n        del data # conserve memory\n        \n        net, optimizer, dataset_iterator = accelerator.prepare(\n            net, optimizer, dataset_iterator\n    )\n        \n    \n    # Train.\n    accelerator.print(f'Training for {total_kimg} kimg...')\n    accelerator.print()\n    cur_nimg = resume_kimg * 1000\n    cur_tick = 0\n    start_time = time.time()\n    time_limit = max_training_time*3600\n    \n    with tqdm(initial = cur_nimg, total = total_kimg*1000, disable = not accelerator.is_main_process) as pbar:\n        while True:\n            total_loss = 0.\n            # Accumulate gradients.\n            optimizer.zero_grad(set_to_none=True)\n            for round_idx in range(num_accumulation_rounds):\n                images = next(dataset_iterator)\n                with accelerator.autocast():\n                    #accelerator.print(images.shape)\n                    loss = net(images)\n                    loss = loss / num_accumulation_rounds\n                    total_loss += loss.item()\n                accelerator.backward(loss)\n            pbar.set_description(f'loss: {total_loss:.4f}')\n            accelerator.wait_for_everyone()\n\n            # Update weights.\n            for g in optimizer.param_groups:\n                g['lr'] = optimizer_kwargs['lr'] * min(cur_nimg / max(lr_rampup_kimg * 1000, 1e-8), 1)\n            for param in net.parameters():\n                if param.grad is not None:\n                    torch.nan_to_num(param.grad, nan=0, posinf=1e5, neginf=-1e5, out=param.grad)\n            optimizer.step()\n\n            # Update EMA.\n            if accelerator.is_local_main_process:\n                ema_halflife_nimg = ema_halflife_kimg * 1000\n                if ema_rampup_ratio is not None:\n                    ema_halflife_nimg = min(ema_halflife_nimg, cur_nimg * ema_rampup_ratio)\n                ema_beta = 0.5 ** (batch_size / max(ema_halflife_nimg, 1e-8))\n                for p_ema, p_net in zip(ema.parameters(), net.parameters()):\n                    p_ema.copy_(p_net.detach().lerp(p_ema, ema_beta))\n\n            cur_nimg += batch_size\n            done = (cur_nimg >= total_kimg * 1000) or (time.time() - start_time > time_limit)\n\n            # Save network snapshot.\n            if (snapshot_ticks is not None) and (done or cur_tick % snapshot_ticks == 0):\n                    \n                if accelerator.is_local_main_process:\n                    data = {\n                        'kimg': cur_nimg//1000,\n                        'model': accelerator.get_state_dict(net),\n                        'opt': optimizer.state_dict(),\n                        'ema': ema.state_dict(),\n                        'scaler': accelerator.scaler.state_dict() if exists(accelerator.scaler) else None,\n                    }\n                    torch.save(data, str(os.path.join(run_dir, f'model-save2.pt')))\n                    del data # conserve memory\n\n            # Update state.\n            cur_tick += 1\n            pbar.update(batch_size)\n            if done:\n                break\n\n    # Done.\n    accelerator.print()\n    accelerator.print('Exiting...')\n\n#----------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2023-08-25T21:12:47.394717Z","iopub.execute_input":"2023-08-25T21:12:47.395115Z","iopub.status.idle":"2023-08-25T21:12:47.426391Z","shell.execute_reply.started":"2023-08-25T21:12:47.395078Z","shell.execute_reply":"2023-08-25T21:12:47.425306Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"notebook_launcher(train, (), num_processes=2)","metadata":{"execution":{"iopub.status.busy":"2023-08-25T21:12:48.301097Z","iopub.execute_input":"2023-08-25T21:12:48.302150Z","iopub.status.idle":"2023-08-25T21:13:24.359257Z","shell.execute_reply.started":"2023-08-25T21:12:48.302109Z","shell.execute_reply":"2023-08-25T21:13:24.351697Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Launching training on 2 GPUs.\nSplitting batches...\nbatch_size: 8, num_accumulation_rounds: 15, batch_gpu_total: 120\nLoading dataset...\nConstructing network...\nSetting up optimizer...\nTraining for 50000 kimg...\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  1%|          | 336000/50000000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9efa3e70b71d4bc49e34b1317852351d"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/denoising_diffusion_pytorch/elucidated_diffusion.py:272: UserWarning: Using a target size (torch.Size([8, 1, 256, 256])) that is different to the input size (torch.Size([8, 2, 256, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n  losses = F.mse_loss(denoised, images, reduction = 'none')\n/opt/conda/lib/python3.10/site-packages/denoising_diffusion_pytorch/elucidated_diffusion.py:272: UserWarning: Using a target size (torch.Size([8, 1, 256, 256])) that is different to the input size (torch.Size([8, 2, 256, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n  losses = F.mse_loss(denoised, images, reduction = 'none')\n/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:200: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.\ngrad.sizes() = [512, 16, 1, 1], strides() = [16, 1, 16, 16]\nbucket_view.sizes() = [512, 16, 1, 1], strides() = [16, 1, 1, 1] (Triggered internally at /usr/local/src/pytorch/torch/csrc/distributed/c10d/reducer.cpp:323.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:200: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.\ngrad.sizes() = [512, 16, 1, 1], strides() = [16, 1, 16, 16]\nbucket_view.sizes() = [512, 16, 1, 1], strides() = [16, 1, 1, 1] (Triggered internally at /usr/local/src/pytorch/torch/csrc/distributed/c10d/reducer.cpp:323.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnotebook_launcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_processes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/launchers.py:154\u001b[0m, in \u001b[0;36mnotebook_launcher\u001b[0;34m(function, args, num_processes, mixed_precision, use_port)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLaunching training on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_processes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m GPUs.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[43mstart_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlauncher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_processes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfork\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ProcessRaisedException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m e\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:197\u001b[0m, in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# Loop on join until it returns True or raises an exception.\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:109\u001b[0m, in \u001b[0;36mProcessContext.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# Wait for any process to fail or all of them to succeed.\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m ready \u001b[38;5;241m=\u001b[39m \u001b[43mmultiprocessing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msentinels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m error_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentinel \u001b[38;5;129;01min\u001b[39;00m ready:\n","File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n","File \u001b[0;32m/opt/conda/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"!pip install segmentation-models-pytorch\nimport segmentation_models_pytorch as smp","metadata":{"execution":{"iopub.status.busy":"2023-08-24T10:48:46.826092Z","iopub.execute_input":"2023-08-24T10:48:46.826448Z","iopub.status.idle":"2023-08-24T10:49:10.932006Z","shell.execute_reply.started":"2023-08-24T10:48:46.826417Z","shell.execute_reply":"2023-08-24T10:49:10.930175Z"}}},{"cell_type":"markdown","source":"def get_Unet():\n    model =  smp.Unet(\n                 encoder_name='resnet34',\n                 encoder_weights='imagenet',\n                 in_channels=1\n                 )\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-08-24T10:53:02.309371Z","iopub.execute_input":"2023-08-24T10:53:02.309770Z","iopub.status.idle":"2023-08-24T10:53:02.316355Z","shell.execute_reply.started":"2023-08-24T10:53:02.309735Z","shell.execute_reply":"2023-08-24T10:53:02.315162Z"}}},{"cell_type":"markdown","source":"import os\nimport time\nimport copy\nimport json\nimport pickle\nimport psutil\nimport numpy as np\nimport torch\n\n#----------------------------------------------------------------------------\n\ndef train(\n    run_dir             = './results',      # Output directory.\n    dataset_options     = {'paths':paths, 'transforms': None, 'limit': 25, 'normalize': True},       # Option for dataset creator \n    network_kwargs      = {},       # Options for model.\n    epochs              = 10,\n    optimizer_kwargs    = {'lr': 1e-4, 'betas': (0.9, 0.99)},       # Options for optimizer.\n    split_batches       = True,     # Split batches?\n    mixes_pecision      = 'fp16',\n    seed                = 12,        # Global random seed.\n    lr_rampup_kimg      = 10000,    # Learning rate ramp-up duration.\n    snapshot_ticks      = 2,       # How often to save network snapshots, None = disable.\n    batch_gpu           = 6      # Limit batch size per GPU, None = no limit.\n):\n\n    # Initialize accelerator.\n    accelerator = Accelerator(\n        split_batches = split_batches,\n        mixed_precision = 'fp16'\n    )\n    device = accelerator.device\n    \n    if accelerator.is_main_process:\n        results_folder = Path(run_dir)\n        results_folder.mkdir(exist_ok = True)\n\n    # Select batch size per GPU.\n    accelerator.print(\"Splitting batches...\")\n    accelerator.print(f\"batch_size: {batch_gpu}\")\n    \n    #mse = nn.MSELoss(reduction='sum').to(accelerator.device)\n    # Load dataset.\n    accelerator.print('Loading dataset...')\n    dataset_obj = construct_dataset(**dataset_options)\n    #dataset_sampler = InfiniteSampler(dataset=dataset_obj, rank=get_rank(), num_replicas=get_world_size(), seed=seed)\n    dataset_iterator = torch.utils.data.DataLoader(dataset=dataset_obj, batch_size=batch_gpu)\n\n    # Construct network.\n    accelerator.print('Constructing network...')\n    net = get_Unet()\n    \n    # Setup optimizer.\n    accelerator.print('Setting up optimizer...')\n    optimizer =  Adam(net.parameters(), **optimizer_kwargs)\n    \n    # Accelerator prepare\n    net, optimizer, dataset_iterator = accelerator.prepare(\n        net, optimizer, dataset_iterator\n    )\n\n    # Train.\n    accelerator.print(f'Training for {epochs} epochs...')\n    accelerator.print()\n    epoch = 0\n    while epoch<epochs:\n        \n        accelerator.print(f\"Epoch {epoch+1}/{epochs}\")\n        net.train()\n        with tqdm(initial = 0, total = len(dataset_obj), disable = not accelerator.is_main_process) as pbar:\n            for images in dataset_iterator:\n                output = net(images)\n                loss = torch.nn.functional.mse_loss(output, images, reduction = 'sum')\n                \n                #accelerator.wait_for_everyone()\n                accelerator.backward(loss)\n                      \n                optimizer.step()\n                optimizer.zero_grad()\n                pbar.set_description(f'loss: {loss:.4f}')\n                pbar.update(batch_gpu)\n            \n            # Save network snapshot.\n            if (snapshot_ticks is not None) and (epoch % snapshot_ticks == 0):\n                if accelerator.is_local_main_process:\n                    with torch.inference_mode():\n                        fig, ax = plt.subplots(2, output.shape[0])\n                        for p in range(output.shape[0]):\n                            ax[0, p].imshow(images[p,:,:].cpu().detach().squeeze().numpy()*255.0)\n                            ax[1, p].imshow(output[p,:,:].cpu().detach().squeeze().numpy()*255.0)\n                        plt.show()\n                    data = {\n                        'epoch': epoch,\n                        'model': accelerator.get_state_dict(net),\n                        'opt': optimizer.state_dict(),\n                        'scaler': accelerator.scaler.state_dict() if exists(accelerator.scaler) else None,\n                    }\n                    torch.save(data, str(os.path.join(run_dir, f'model-{epoch}.pt')))\n                    del data # conserve memory\n\n        if accelerator.is_local_main_process:\n            epoch += 1\n    # Done.\n    accelerator.print()\n    accelerator.print('Exiting...')\n\n#----------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2023-08-24T11:03:53.689978Z","iopub.execute_input":"2023-08-24T11:03:53.690590Z","iopub.status.idle":"2023-08-24T11:03:53.763059Z","shell.execute_reply.started":"2023-08-24T11:03:53.690538Z","shell.execute_reply":"2023-08-24T11:03:53.761431Z"}}},{"cell_type":"markdown","source":"notebook_launcher(train, (), num_processes=2)","metadata":{"execution":{"iopub.status.busy":"2023-08-24T11:03:53.831637Z","iopub.execute_input":"2023-08-24T11:03:53.832316Z","iopub.status.idle":"2023-08-24T11:04:46.380902Z","shell.execute_reply.started":"2023-08-24T11:03:53.832250Z","shell.execute_reply":"2023-08-24T11:04:46.376047Z"}}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}